name: 🧪 Comprehensive Testing Pipeline

on:
  push:
    branches: [main, develop, master]
  pull_request:
    types: [opened, synchronize, reopened]
  schedule:
    # Run full test suite nightly at 2 AM UTC
    - cron: '0 2 * * *'

env:
  NODE_VERSION: '18'
  CACHE_DEPENDENCIES_PATH: |
    node_modules
    ~/.npm
  
jobs:
  # Job 1: Code Quality & Fast Tests
  quality-gate:
    name: 🎯 Quality Gate
    runs-on: ubuntu-latest
    timeout-minutes: 15
    outputs:
      should-run-full-suite: ${{ steps.changes.outputs.src }}
    
    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: 🔍 Detect changes
        uses: dorny/paths-filter@v2
        id: changes
        with:
          filters: |
            src:
              - 'src/**'
              - '**/*.test.*'
              - '**/*.spec.*'
              - 'package*.json'
              - 'vite.config.ts'
              - 'tsconfig.json'

      - name: ⚡ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: 📦 Install dependencies
        run: npm ci --prefer-offline --no-audit

      - name: 🔧 TypeScript check
        run: npm run type-check

      - name: 🎨 Lint check
        run: npm run lint

      - name: 💅 Format check
        run: npm run format:check

      - name: ⚡ Fast unit tests
        run: npm run test:run -- --reporter=verbose --run --coverage=false
        timeout-minutes: 5

  # Job 2: Comprehensive Unit & Integration Tests
  unit-integration-tests:
    name: 🧪 Unit & Integration Tests
    runs-on: ubuntu-latest
    needs: quality-gate
    if: needs.quality-gate.outputs.should-run-full-suite == 'true'
    timeout-minutes: 20
    strategy:
      matrix:
        test-group: ['unit', 'integration', 'services', 'components']
    
    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4

      - name: ⚡ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: 📦 Install dependencies
        run: npm ci --prefer-offline --no-audit

      - name: 🧪 Run ${{ matrix.test-group }} tests
        run: |
          case "${{ matrix.test-group }}" in
            "unit")
              npm run test:run -- --reporter=verbose src/__tests__/components src/__tests__/hooks src/__tests__/utils
              ;;
            "integration") 
              npm run test:run -- --reporter=verbose src/__tests__/integration
              ;;
            "services")
              npm run test:run -- --reporter=verbose src/__tests__/services
              ;;
            "components")
              npm run test:run -- --reporter=verbose src/__tests__/context
              ;;
          esac

      - name: 📊 Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results-${{ matrix.test-group }}
          path: |
            coverage/
            test-results.xml
          retention-days: 7

  # Job 3: Advanced Testing (Visual, A11y, Performance)
  advanced-testing:
    name: 🚀 Advanced Testing Suite
    runs-on: ubuntu-latest
    needs: quality-gate
    if: needs.quality-gate.outputs.should-run-full-suite == 'true'
    timeout-minutes: 25
    
    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4

      - name: ⚡ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: 📦 Install dependencies
        run: npm ci --prefer-offline --no-audit

      - name: 🎨 Visual Regression Tests
        run: npm run test:run -- --reporter=verbose src/__tests__/visual
        continue-on-error: true

      - name: ♿ Accessibility Tests
        run: npm run test:run -- --reporter=verbose src/__tests__/accessibility
        continue-on-error: true

      - name: ⚡ Performance Tests
        run: npm run test:run -- --reporter=verbose src/__tests__/performance
        continue-on-error: true

      - name: 📊 Upload advanced test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: advanced-test-results
          path: |
            visual-diff/
            a11y-reports/
            performance-reports/
          retention-days: 7

  # Job 4: End-to-End Tests
  e2e-tests:
    name: 🌐 E2E Tests
    runs-on: ubuntu-latest
    needs: [quality-gate, unit-integration-tests]
    if: needs.quality-gate.outputs.should-run-full-suite == 'true'
    timeout-minutes: 30
    
    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4

      - name: ⚡ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: 📦 Install dependencies
        run: npm ci --prefer-offline --no-audit

      - name: 🎭 Install Playwright
        run: npx playwright install --with-deps

      - name: 🏗️ Build application
        run: npm run build

      - name: 🌐 Run E2E tests
        run: npm run e2e
        env:
          CI: true

      - name: 📊 Upload E2E results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: e2e-results
          path: |
            playwright-report/
            test-results/
          retention-days: 7

  # Job 5: Coverage Analysis
  coverage-analysis:
    name: 📊 Coverage Analysis
    runs-on: ubuntu-latest
    needs: [unit-integration-tests]
    if: always() && needs.quality-gate.outputs.should-run-full-suite == 'true'
    timeout-minutes: 15
    
    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4

      - name: ⚡ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: 📦 Install dependencies
        run: npm ci --prefer-offline --no-audit

      - name: 📊 Generate coverage report
        run: npm run test:coverage -- --reporter=verbose

      - name: 📈 Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage/lcov.info
          fail_ci_if_error: false
          verbose: true

      - name: 🎯 Coverage requirements check
        run: |
          # Check coverage thresholds
          node -e "
          const fs = require('fs');
          const coverage = JSON.parse(fs.readFileSync('coverage/coverage-summary.json'));
          const thresholds = {
            statements: 90,
            branches: 85,
            functions: 90,
            lines: 90
          };
          
          let failed = false;
          Object.entries(thresholds).forEach(([key, threshold]) => {
            const actual = coverage.total[key].pct;
            if (actual < threshold) {
              console.error(\`❌ \${key} coverage \${actual}% is below threshold \${threshold}%\`);
              failed = true;
            } else {
              console.log(\`✅ \${key} coverage \${actual}% meets threshold \${threshold}%\`);
            }
          });
          
          if (failed) process.exit(1);
          "

  # Job 6: Mutation Testing (Weekly)
  mutation-testing:
    name: 🧬 Mutation Testing
    runs-on: ubuntu-latest
    needs: quality-gate
    if: github.event_name == 'schedule' || contains(github.event.head_commit.message, '[mutation]')
    timeout-minutes: 60
    
    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4

      - name: ⚡ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: 📦 Install dependencies
        run: |
          npm ci --prefer-offline --no-audit
          npm install -g stryker-cli @stryker-mutator/core @stryker-mutator/vitest-runner

      - name: 🧬 Run mutation tests
        run: stryker run src/__tests__/mutation/mutation-testing.config.js
        continue-on-error: true

      - name: 📊 Upload mutation report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: mutation-testing-report
          path: reports/mutation/
          retention-days: 30

  # Job 7: Performance Benchmarking
  performance-benchmarking:
    name: ⚡ Performance Benchmarking
    runs-on: ubuntu-latest
    needs: quality-gate
    if: github.event_name == 'pull_request' || github.event_name == 'schedule'
    timeout-minutes: 20
    
    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4

      - name: ⚡ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: 📦 Install dependencies
        run: npm ci --prefer-offline --no-audit

      - name: 🏗️ Build for performance testing
        run: npm run build

      - name: ⚡ Run performance benchmarks
        run: |
          # Bundle size analysis
          npm run analyze
          
          # Runtime performance tests
          npm run test:run -- src/__tests__/performance --reporter=verbose

      - name: 📊 Performance regression check
        run: |
          echo "🎯 Performance Benchmarks:"
          echo "Bundle size should be < 2MB"
          echo "Initial load should be < 3s"
          echo "Component render should be < 100ms"

  # Job 8: Security Testing
  security-testing:
    name: 🛡️ Security Testing
    runs-on: ubuntu-latest
    needs: quality-gate
    timeout-minutes: 15
    
    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4

      - name: 🛡️ Run security audit
        run: npm audit --audit-level=moderate

      - name: 🔍 Dependency vulnerability scan
        uses: actions/dependency-review-action@v3
        if: github.event_name == 'pull_request'

      - name: 🛡️ CodeQL security analysis
        uses: github/codeql-action/analyze@v2
        with:
          languages: javascript
        continue-on-error: true

  # Job 9: Test Results Summary
  test-summary:
    name: 📋 Test Results Summary
    runs-on: ubuntu-latest
    needs: [quality-gate, unit-integration-tests, advanced-testing, e2e-tests, coverage-analysis]
    if: always()
    
    steps:
      - name: 📊 Download all test artifacts
        uses: actions/download-artifact@v4
        with:
          path: ./test-artifacts

      - name: 📋 Generate test summary
        run: |
          echo "## 🧪 Test Results Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [[ "${{ needs.quality-gate.result }}" == "success" ]]; then
            echo "✅ **Quality Gate**: Passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **Quality Gate**: Failed" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [[ "${{ needs.unit-integration-tests.result }}" == "success" ]]; then
            echo "✅ **Unit & Integration Tests**: Passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **Unit & Integration Tests**: Failed" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [[ "${{ needs.advanced-testing.result }}" == "success" ]]; then
            echo "✅ **Advanced Testing**: Passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "⚠️ **Advanced Testing**: Some issues detected" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [[ "${{ needs.e2e-tests.result }}" == "success" ]]; then
            echo "✅ **E2E Tests**: Passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **E2E Tests**: Failed" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [[ "${{ needs.coverage-analysis.result }}" == "success" ]]; then
            echo "✅ **Coverage Requirements**: Met" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **Coverage Requirements**: Not met" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "📊 **Detailed reports available in workflow artifacts**" >> $GITHUB_STEP_SUMMARY

      - name: 💬 Comment on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const summary = `## 🧪 Testing Pipeline Results
            
            | Test Suite | Status |
            |------------|--------|
            | Quality Gate | ${{ needs.quality-gate.result == 'success' && '✅ Passed' || '❌ Failed' }} |
            | Unit & Integration | ${{ needs.unit-integration-tests.result == 'success' && '✅ Passed' || '❌ Failed' }} |
            | Advanced Testing | ${{ needs.advanced-testing.result == 'success' && '✅ Passed' || '⚠️ Issues' }} |
            | E2E Tests | ${{ needs.e2e-tests.result == 'success' && '✅ Passed' || '❌ Failed' }} |
            | Coverage | ${{ needs.coverage-analysis.result == 'success' && '✅ Met' || '❌ Below threshold' }} |
            
            📊 Detailed reports are available in the [workflow artifacts](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}).
            `;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: summary
            });

# Workflow completion notification
concurrency:
  group: testing-${{ github.ref }}
  cancel-in-progress: true